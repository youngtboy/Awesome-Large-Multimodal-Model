# Awesome-Large-Multimodal-Model
A paper list of large multimodal model (large vision-language model) 

## 2023

| Name | Pub.  | Title | Links |
|-------------------|---------|---------------------------|-----------|
| LLaVA | NIPS'23  | **Visual Instruction Tuning**  <br>  <sub>*Haotian Liu, Chunyuan Li, Qingyang Wu, Yong Jae Lee* | [Paper](https://arxiv.org/abs/2304.08485) / [Code](https://github.com/haotian-liu/LLaVA) |
| Emu1 | ICLR'24  | **Emu: Generative Pretraining in Multimodality**  <br>  <sub>*Quan Sun, Qiying Yu, Yufeng Cui, Fan Zhang, Xiaosong Zhang, Yueze Wang, Hongcheng Gao, Jingjing Liu, Tiejun Huang, Xinlong Wang* | [Paper](https://arxiv.org/abs/2307.05222) / [Code](https://github.com/baaivision/Emu) |
